<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <!-- <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/> -->
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="SocialNav with GPS Curriculum">
  <meta name="twitter:description" content="SocialNav with GPS Curriculum">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <!-- <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE"> -->
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Social Navigation with Sparse GPS via Curriculum-Induced RL</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Curriculum Learning for GPS-Free Indoor Social Navigation</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://gchhablani.github.io/" target="_blank">Gunjan Chhablani</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Madhura Keshava Ummettuguli</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Siva Kailas</a><sup>*</sup>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Georgia Tech</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <!-- <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span> -->

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/gchhablani/socnav" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Tasks involving human-robot interaction demand seamless collaboration between the two within indoor settings. Habitat 3.0 introduced a novel Social Navigation task where agents find, track, and follow humans while avoiding collisions. Their baselines show that performance relies heavily on human GPS availability. However, indoor GPS sensors are rarely reliable in real-life and it may be impractical to provide GPS for every human in the scene. In this work, we tackle the issue of realistic social navigation by relaxing the human GPS requirement at every time step. We achieve this via a curriculum learning strategy for training an RL policy capable of finding and tracking humans with sparse or no reliance on human GPS observations. Our experiments demonstrate the effectiveness of our curriculum strategy, achieving comparable performance to the baselines with lesser samples, using a single GPS observation at the beginning of the episode. The project website and videos can be found at gchhablani.github.io/socnav-curr.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!--Introduction-->
<section class="section hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered has-text-justified">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Introduction</h2>
          <p>
            Embodied navigation in indoor environments poses a significant challenge in robotics and AI. Recent advancements in deep
            reinforcement learning have been applied to tackle this challenge. However, many existing approaches rely on the
            assumption that the GPS location of the goal is always available, which is often impractical in real-world scenarios.
            <br>
            <br>
            In this work, we introduce a novel approach aimed at addressing this limitation. Building upon the Social Navigation
            (SocialNav) task proposed by Habitat 3.0, where an agent navigates indoor environments alongside humans, we propose a
            curriculum-based learning strategy. This strategy gradually introduces the agent to increasingly challenging scenarios
            with infrequent access to human GPS locations, mirroring real-world conditions.
            <br>
            <br>
            Our approach draws inspiration from curriculum learning techniques, which start with simpler versions of a task and
            progressively increase complexity. By adapting this concept to focus on human GPS availability, we demonstrate that our
            agent can achieve comparable performance to those with constant GPS access, reaching peak performance faster.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!--End Introduction-->

<!--Methodology-->
<section class="section hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <!-- Paper video. -->
      <div class="columns is-centered has-text-centered has-text-justified">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Methodology</h2>
          <p>
            In our methodology, we adopt the standard reinforcement learning (RL) framework, as utilized in Habitat 3.0, to
            model the Social Navigation (SocialNav) task as a partially-observable Markov Decision Process. Our observation space
            comprises four simulation sensors: an arm depth camera, an arm RGB camera, a humanoid detector, and a humanoid GPS
            sensor.
            <br><br>
            To explore scenarios with limited GPS availability, we introduce two strategies for representing human GPS locations
            when unavailable:
            <br><br>
              <li> <b>ZeroGPS</b>: Providing coordinates (0, 0) instead of GPS data.</li>
              <li> <b>LastGPS</b>: Utilizing the last known GPS location.</li>
            <br>
            In the absence of human GPS information, the success rate of finding significantly decreases, as shown in Habitat 3.0 paper. Thus, we propose a
            curriculum-based approach to adaptively train the agent, hypothesizing that a policy relying consistently on GPS
            information lacks adaptability.
            <br><br>
            Our curriculum design gradually reduces the frequency of GPS availability based on predetermined upper and lower success
            rate thresholds. This process aims to challenge the agent progressively until it can perform optimally without GPS
            assistance. We set the curriculum level K in the range of [1, 1500], determining the interval in the episode where the
            agent has access to current GPS sensor data.
            <br><br>
            Training spans 300 million steps, with curriculum adjustments made every 10 million steps. We incorporate a warm-up
            phase of 10 million steps to ensure the agent attains satisfactory performance under full GPS conditions. Upper success
            rate thresholds are set at 0.9, while lower thresholds vary from 0.8 to 0.88 across training phases.
            <br><br>
            To update the curriculum, we explore three approaches:
            <br><br>
              <li><code>Additive</code>: Incrementing (+50) or decrementing (-25) a fixed value based on finding success rate.</li>
              <li><code>Multiplicative</code>: Doubling or halving the current GPS frequency based on finding success rate.</li>
              <li><code>Dynamic Additive</code>: Adding or subtracting a dynamic value scaling with training finding success rate.</li>
            <br>
            By employing this methodology, we aim to train an adaptive agent capable of navigating SocialNav tasks with limited
            reliance on GPS information.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!--Methodology ends-->

<!--Experiments-->
<section class="section hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <!-- Paper video. -->
      <div class="columns is-centered has-text-centered has-text-justified">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Experiments</h2>
          <h3 class="subtitle is-4">Metrics and Evaluation</h3>
          <p>We assess our policies through 500 unseen episodes, utilizing evaluation metrics borrowed from prior work [11]. In
            ZeroGPS evaluation, a fixed GPS observation of (0,0) is assumed at each step, while LastGPS receives only the initial
            human GPS at every time step.</p>
            <br><br>
            <h3 class="subtitle is-4">Baselines</h3>
            <p>We establish two baseline models: FullGPS (Human GPS observed at every timestep), and NoGPS (No GPS sensor).
              Evaluation results depicted in the figure below reveal that while the NoGPS baseline achieves a respectable 0.92 evaluation
              finding success (eval FS), its performance is inconsistent. Conversely, FullGPS consistently achieves near-perfect
              performance with a 0.98 eval FS.</p>
            <img src="static/images/fs_plot_eai_workshop.png" alt="Figure 1: Eval FS for best-performing curriculum policies">
            <table border="1">
              <caption>Table 1: Evaluation results on checkpoints with the highest FS.</caption>
              <thead>
                <tr>
                  <th>Experiment</th>
                  <th>FS (↑)</th>
                  <th>FR (↑)</th>
                  <th>SPS (↑)</th>
                  <th>CR (↓)</th>
                  <th>R (↑)</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>NoGPS</td>
                  <td>0.92</td>
                  <td>0.72</td>
                  <td>0.52</td>
                  <td>0.52</td>
                  <td>6770.28</td>
                </tr>
                <tr>
                  <td>FullGPS</td>
                  <td>0.98</td>
                  <td>0.68</td>
                  <td>0.52</td>
                  <td>0.59</td>
                  <td>6079.23</td>
                </tr>
                <tr>
                  <td>Mul (ZGPS)</td>
                  <td>0.52</td>
                  <td>0.06</td>
                  <td>0.02</td>
                  <td>0.40</td>
                  <td>31.07</td>
                </tr>
                <tr>
                  <td>Add (ZGPS)</td>
                  <td>0.92</td>
                  <td>0.66</td>
                  <td>0.44</td>
                  <td>0.60</td>
                  <td>4941.44</td>
                </tr>
                <tr>
                  <td>Dyn-Add (ZGPS)</td>
                  <td>0.89</td>
                  <td>0.60</td>
                  <td>0.41</td>
                  <td>0.63</td>
                  <td>4784.58</td>
                </tr>
                <tr>
                  <td>Mul-LGPS</td>
                  <td>0.92</td>
                  <td>0.63</td>
                  <td>0.38</td>
                  <td>0.64</td>
                  <td>4044.00</td>
                </tr>
                <tr>
                  <td>Dyn-Add-LGPS</td>
                  <td>0.92</td>
                  <td>0.65</td>
                  <td>0.44</td>
                  <td>0.62</td>
                  <td>5364.39</td>
                </tr>
                <tr>
                  <td>Add-LGPS</td>
                  <td>0.91</td>
                  <td>0.71</td>
                  <td>0.51</td>
                  <td>0.54</td>
                  <td>6605.48</td>
                </tr>
              </tbody>
            </table>
            <br><br>
            <h3 class="subtitle is-4">Zero GPS vs Last GPS</h3>
            For brevity, we focus on the top two curriculum strategies in the figure above. <b>LastGPS</b> <code>Dyn-Add</code> outperforms <b>ZeroGPS</b> <code>Add</code>,
            requiring fewer iterations for similar performance, indicating its higher sample efficiency. Table 1 confirms the
            superior performance of <b>LastGPS</b> over <b>ZeroGPS</b>. This result likely stems from <b>ZeroGPS</b> needing to implicitly remember the
            latest human GPS observation, whereas <b>LastGPS</b> continually receives the cached human GPS.
            <br><br>
            <h3 class="subtitle is-4">Additive vs Multiplicative vs Dynamic Additive</h3>
            We observe that FS for <code>Add</code> and <code>Dyn-Add</code> reaches 0.92. <code>Mul</code> strategy performs poorly with <b>ZeroGPS</b> (0.52 FS)
            but well with <b>LastGPS</b> (0.92 FS). If the difficulty updates too rapidly, as in <code>Mul</code>, it can exacerbate the learning curve.
            Since <b>LastGPS</b> is easier than the <b>ZeroGPS</b> setting (see Section 3.3), the combination of <code>Mul</code> and <b>ZeroGPS</b> results in a
            curriculum that is too difficult.
            <br><br>
            <h3 class="subtitle is-4">GPS vs Baselines</h3>
            The figure illustrates that our best curriculum strategies (<code>Add-Curr</code> and <code>Dyn-Add-Curr-LGPS</code>) perform as well as the NoGPS
            baseline but reach high performance early in training. We also observe more stable curves compared to the NoGPS baseline
            towards the end of training, indicating that curriculum learning aids in developing a robust policy with minimal samples
            while mitigating reliance on GPS availability.
        </div>
      </div>
    </div>
  </div>
</section>
<!--Experiments end-->

  <!-- Youtube video -->
<section class="section hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <!-- Paper video. -->
      <div class="columns is-centered has-text-centered has-text-justified">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Evaluation Trajectories</h2>
          <div class="columns">
            <!-- First video -->
            <div class="column">
              <div class="publication-video">
                <!-- First video iframe -->
                <iframe src="https://www.youtube.com/embed/N-Mm8EltLII" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
              </div>
            </div>
            <!-- Second video -->
            <div class="column">
              <div class="publication-video">
                <!-- Second video iframe -->
                <iframe src="https://www.youtube.com/embed/dMcuzPC_GK4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
              </div>
            </div>
          </div>
          <br>
          <p>
          In the above episode, we can see that the NoGPS agent keeps moving in circles waiting for human and then when it is
          following the human, finally it collides while trying to avoid, ending the episode very soon. In contract, the dynamic
          additive agent trained with curriculum learning is able to find the human quickly, follow it for longer while avoiding
          collisions. Although, the episode ends when it gets stuck within walls and times out.
          </p>
          <br>
          <div class="columns">
            <!-- First video -->
            <div class="column">
              <div class="publication-video">
                <!-- First video iframe -->
                <iframe src="https://www.youtube.com/embed/I-QJZKacExE" frameborder="0" allow="autoplay; encrypted-media"
                  allowfullscreen width="100%" height="315"></iframe>
              </div>
            </div>
            <!-- Second video -->
            <div class="column">
              <div class="publication-video">
                <!-- Second video iframe -->
                <iframe src="https://www.youtube.com/embed/V7yGChciRe4" frameborder="0" allow="autoplay; encrypted-media"
                  allowfullscreen width="100%" height="315"></iframe>
              </div>
            </div>
            <!-- Third video -->
            <div class="column">
              <div class="publication-video">
                <!-- Third video iframe -->
                <iframe src="https://www.youtube.com/embed/cwBzyDR7fsY" frameborder="0" allow="autoplay; encrypted-media"
                  allowfullscreen width="100%" height="315"></iframe>
              </div>
            </div>
          </div>
          <br>
          <p>
          In the above episode, we see that the NoGPS agent and dynamic additive LastGPS agent perform similarly and are able to
          find the human and follow for a long duration. However, the zero GPS additive agent collides pretty early in the
          episode, although it is still able to find the human reasonably early in the episode. This suggests that ZeroGPS is
          harder compared to LastGPS setting as the agent has no information after the first step of any GPS sensor. NoGPS agent
          stays in place rotating and waiting for human, while the dynamic additive LastGPS agent has some navigation ability and
          finds the human earlier than NoGPS.
          </p>
          <br>
          <div class="columns">
            <!-- First video -->
            <div class="column">
              <div class="publication-video">
                <!-- First video iframe -->
                <iframe src="https://www.youtube.com/embed/juksJNybAlQ" frameborder="0" allow="autoplay; encrypted-media"
                  allowfullscreen width="100%" height="315"></iframe>
              </div>
            </div>
            <!-- Second video -->
            <div class="column">
              <div class="publication-video">
                <!-- Second video iframe -->
                <iframe src="https://www.youtube.com/embed/kfftwt56GhM" frameborder="0" allow="autoplay; encrypted-media"
                  allowfullscreen width="100%" height="315"></iframe>
              </div>
            </div>
            <!-- Third video -->
            <div class="column">
              <div class="publication-video">
                <!-- Third video iframe -->
                <iframe src="https://www.youtube.com/embed/8zsqzotEjqs" frameborder="0" allow="autoplay; encrypted-media"
                  allowfullscreen width="100%" height="315"></iframe>
              </div>
            </div>
          </div>
          <br>
          </p>
          In the above episode, the agent fails pretty early for NoGPS due to collision and the agent keeps rotating initially
          without trying to navigate the human. In comparison, the additive ZeroGPS and the dynamic additive LastGPS agents do a
          good job of finding the human (going right instead of left like NoGPS) and then follow the human for a good number of
          steps, albeit ending in collision.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End youtube video -->



  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            <!-- You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>. -->
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>


  


<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
